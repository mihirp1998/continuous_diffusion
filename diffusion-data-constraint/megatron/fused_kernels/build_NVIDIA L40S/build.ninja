ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda-12.9/bin/nvcc

cflags = -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1018\" -isystem /data/user_data/mprabhud/mamba/envs/cont/lib/python3.12/site-packages/torch/include -isystem /data/user_data/mprabhud/mamba/envs/cont/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-12.9/include -isystem /data/user_data/mprabhud/mamba/envs/cont/include/python3.12 -fPIC -std=c++17 -O3
post_cflags = 
cuda_cflags = -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1018\" -isystem /data/user_data/mprabhud/mamba/envs/cont/lib/python3.12/site-packages/torch/include -isystem /data/user_data/mprabhud/mamba/envs/cont/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda-12.9/include -isystem /data/user_data/mprabhud/mamba/envs/cont/include/python3.12 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_100,code=sm_100 -std=c++17
cuda_post_cflags = 
cuda_dlink_post_cflags = 
sycl_dlink_post_cflags = 
ldflags = -shared -L/data/user_data/mprabhud/mamba/envs/cont/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-12.9/lib64 -lcudart

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc --generate-dependencies-with-compile --dependency-output $out.d $cuda_cflags -c $in -o $out $cuda_post_cflags





rule link
  command = $cxx $in $ldflags -o $out

build scaled_softmax.o: compile /home/mprabhud/phd_projects/continuous_diffusion/diffusion-data-constraint/megatron/fused_kernels/scaled_softmax.cpp
build scaled_softmax_cuda.cuda.o: cuda_compile /home/mprabhud/phd_projects/continuous_diffusion/diffusion-data-constraint/megatron/fused_kernels/scaled_softmax_cuda.cu





build scaled_softmax_cuda.so: link scaled_softmax.o scaled_softmax_cuda.cuda.o

default scaled_softmax_cuda.so
